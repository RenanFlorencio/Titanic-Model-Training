{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIMPEZA DOS DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregando e fazendo visualizações iniciais\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test_y = pd.read_csv(\"gender_submission.csv\")\n",
    "df.set_index('PassengerId')\n",
    "test_y.set_index('PassengerId')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.nunique()) # Verificando a quantidade de valores nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se pode verificar que não há discrepâncias claras de quantidade de valores categoricos parar as colunas categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificação dos valores nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAIN:\")\n",
    "print(df.isna().sum()) # Verificando se há valores nulos\n",
    "print(\"TEST:\")\n",
    "print(test.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos uma grande quantidade de valores nulos em Cabin, o que indica que remover a coluna seria uma boa escolha. Além disso, precisamos encontrar uma maneira de tratar as idades que estão faltando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificação das correlações:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl = df.drop('PassengerId', axis=1)\n",
    "sb.heatmap(correl.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do heatmap não foi possível encontrar boas correlações e nem mesmo uma boa coluna a partir da qual inferir os valores de idade que estão faltando no dataset original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Verificação dos valores categóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As colunas Ticket, Name e Cabin podem ser removidas por serem inerentemente irrelevantes. A coluna Embarked também não parece ser relevante para a análise final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Name', 'Cabin', 'Ticket', 'Embarked']\n",
    "df.drop(cols, axis=1, inplace=True)\n",
    "test.drop(cols, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, basta substituir os valores dos sexos para 0: male e 1: female. Por termos baixa cardinalidade, é possível usar um One-Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_enc = OneHotEncoder()\n",
    "df_hot = pd.get_dummies(df['Sex'])\n",
    "test_hot = pd.get_dummies(test['Sex'])\n",
    "\n",
    "df = df.drop(['Sex'], axis='columns')\n",
    "test = test.drop(['Sex'], axis='columns')\n",
    "\n",
    "df = pd.concat([df, df_hot], axis='columns')\n",
    "test = pd.concat([test, test_hot], axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Análise de Outliers para o treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe para verificar outliers\n",
    "out = df.drop(['female', 'male', 'PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=out.columns.size, figsize=(20,5))\n",
    "for i in range(out.columns.size):\n",
    "    sb.boxplot(data=out.iloc[:, i], ax=axs[i])\n",
    "    axs[i].set_title(out.columns[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos ver que existem dois valores de outliers para a idade, alguns para SibSp e Parch e muitos para Fare. Nesse caso, não tendo descartado passenger anteriormente, talvez esse seja um bom motivo. Embora passageiros que tenham pago mais possam estar acomodadas em locais específicos que podem ter sido mais ou menos afetados, essa informação também deve estar representada em Pclass, no entanto, o mapa de correlação visto anteriormente nos diz que Fare tem uma das melhores relações com Survived, portanto talvez não seja razoável removê-la. À princípio, irei removê-la, mas também é possível realizar teste com a coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Fare', axis=1, inplace=True)\n",
    "test.drop('Fare', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por cautela, podemos verificar a contagem de passageiros para cada valor de SibSp e Parch a partir dos valores que estão fora dos desvios padrão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parch\")\n",
    "for i in range(1, df['Parch'].max()):\n",
    "    print(f'{i}:', len(df[df['Parch'] == i]))\n",
    "\n",
    "print(\"SibSp\")\n",
    "for i in range(2, df['SibSp'].max()):\n",
    "    print(f'{i}:', len(df[df['SibSp'] == i]))\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Aqui podemos ver que é razoável remover os outliers a partir de 3 em Parch e a partir de 3 em SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Parch'] <= 3) & (df['SibSp'] <= 3)]\n",
    "out = df.drop(['female', 'male', 'PassengerId', 'Survived'], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=out.columns.size, figsize=(20,5))\n",
    "for i in range(out.columns.size):\n",
    "    sb.boxplot(data=out.iloc[:, i], ax=axs[i])\n",
    "    axs[i].set_title(out.columns[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim removemos a maior parte dos outliers sem remover uma quantidade extremamente grande de linhas da tabela."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, precisamos encontrar uma forma de ajustar os valores perdidos de idade. À princípio, podemos imputar os valores com base na média. É interessante notar que o dataset de teste também possui idades não preenchidas. Nesse caso, no entanto, é melhor remover as linhas, haja visto que precisamos testar com dados completos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer()\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df))\n",
    "\n",
    "# Devolvendo os nomes das colunas:\n",
    "df_imputed.columns = df.columns\n",
    "df_imputed.set_index('PassengerId')\n",
    "print(df_imputed.head())\n",
    "print(df_imputed.isna().sum())\n",
    "print(\"Média idade: \", df['Age'].mean())\n",
    "df = df_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[~test['Age'].isna()]\n",
    "test_y = test_y[test_y.PassengerId.isin(test.PassengerId)] # Removendo os valores da resposta\n",
    "print(test_y.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dataframe para verificar outliers\n",
    "out = df.drop(['female', 'male', 'PassengerId'], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=out.columns.size, figsize=(20,5))\n",
    "for i in range(out.columns.size):\n",
    "    sb.boxplot(data=out.iloc[:, i], ax=axs[i])\n",
    "    axs[i].set_title(out.columns[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PassengerId'] = df['PassengerId'].astype(int) # Corrigindo o tipo do Id\n",
    "df = df.set_index('PassengerId')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos a nova tabela pronta para ser treinada pelos modelos de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('PassengerId')\n",
    "test_y = test_y.set_index('PassengerId')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREINANDO MODELOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora já temos datasets de treino e de teste e podemos começar a comparar modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "RandomForest"
    ]
   },
   "source": [
    "- #### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, mean_absolute_error, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, precisamos separar os datasets em treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Survived', axis=1)\n",
    "y = df.Survived\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E também façamos o Min-Max Scaling da variável Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max = train_x['Age'].max()\n",
    "min = train_x['Age'].min()\n",
    "\n",
    "for i in range(train_x['Age'].size):\n",
    "    train_x['Age'].iloc[[i]] = (train_x['Age'].iloc[[i]] - min) / (max - min)\n",
    "\n",
    "print(train_x['Age'].max())\n",
    "print(train_x['Age'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar o balanceamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de 0s: 61%\n",
      "Porcentagem de 1s: 39%\n"
     ]
    }
   ],
   "source": [
    "print(f'Porcentagem de 0s: {round((train_y[train_y == 0].count() / train_y.shape[0]) * 100)}%')\n",
    "print(f'Porcentagem de 1s: {round((train_y[train_y == 1].count() / train_y.shape[0]) * 100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o balanceamento não esteja perfeito, deve ser suficiente para uma boa predição dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora implementando o modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=1, n_estimators=1000, criterion='log_loss')\n",
    "rf.fit(train_x, train_y)\n",
    "\n",
    "# Observando o erro no treinamento\n",
    "predict = rf.predict(val_x)\n",
    "rf_f1 = f1_score(predict, val_y)\n",
    "print(\"Validation f1-score for Random Forest: {}\".format(rf_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos um erro aproximadamente razoável, para o modelo treinado com o subset de treino e validação, vamos ver como ele lida com as previsões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, como estamos lidando com uma saída booleana, podemos verificar outras métricas de assertividade do modelo.\n",
    "\n",
    "Nesse caso, Accuracy, Precision e Recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificação de métricas\n",
    "def metricas(modelo):\n",
    "    valores_corretos = np.array(test_y.squeeze())\n",
    "    predict_final = modelo.predict(test)\n",
    "\n",
    "    acc = accuracy_score(predict_final, valores_corretos)\n",
    "    recall = recall_score(predict_final, valores_corretos)\n",
    "    precision = precision_score(predict_final, valores_corretos)\n",
    "    f1score = f1_score(predict_final, valores_corretos)\n",
    "\n",
    "    print(f'Accuracy: {round(acc * 100)}%')\n",
    "    print(f'Precision: {round(precision * 100)}%')\n",
    "    print(f'Recall: {round(recall * 100)}%')\n",
    "    print(f'f1-score: {round(f1score * 100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui verificamos boa acurácia, mediano f1-score e ótimo recall, embora tenhamos precisão razoável. Isso significa que o modelo não tem muitos false negatives, ou seja, é um modelo conservador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste de hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos fazer testes com diferentes parâmetros para as árvores para verificar se podemos encontrar algum modelo mais adequado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramento, uma floresta com 200 árvores e critério de erro \"gini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestClassifier(n_estimators=200, criterion=\"gini\", verbose=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2.fit(train_x, train_y)\n",
    "\n",
    "predict = rf_2.predict(val_x)\n",
    "rf_f1 = f1_score(predict, val_y)\n",
    "print(\"f1-score para o conjunto de validação:\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(rf_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui não vemos muitas mudanças na capacidade de predição do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, uma floresta com 300 árvores usando entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3 = RandomForestClassifier(n_estimators=300, criterion=\"entropy\", verbose=0, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3.fit(train_x, train_y)\n",
    "\n",
    "predict = rf_3.predict(val_x)\n",
    "rf_f1 = f1_score(predict, val_y)\n",
    "print(\"f-1 score para o conjunto de validação:\", rf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas(rf_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, não se observa grandes mudanças no modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### LOGISTIC REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score for Logistic Regression training: 0.0\n",
      "Accuracy for Logistic Regression training: 0.5915492957746479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', class_weight=None)\n",
    "\n",
    "lr.fit(train_x, train_y)\n",
    "predict = lr.predict(val_x)\n",
    "print(f'f1-score for Logistic Regression training: {f1_score(predict, val_y)}')\n",
    "print(f'Accuracy for Logistic Regression training: {accuracy_score(predict, val_y)}')\n",
    "\n",
    "predict[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que o modelo está prevendo sempre o valor 0, o que mantém o f1 score em 0, por não ter recall, mas garante uma acurácia razoável. Isso pode ser um indicativo de que os datasets de treino estão mal balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um undersampling para tentar melhorar os resultados de previsão do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 1s: 251\n",
      "Number of 0s: 387\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[0] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\renae\\OneDrive\\Documentos\\Academicos\\MachineLearning\\titanic\\training.ipynb Cell 71\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y144sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of 1s: \u001b[39m\u001b[39m{\u001b[39;00mtrain_y[train_y\u001b[39m \u001b[39m\u001b[39m==\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcount()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y144sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNumber of 0s: \u001b[39m\u001b[39m{\u001b[39;00mtrain_y[train_y\u001b[39m \u001b[39m\u001b[39m==\u001b[39m\u001b[39m \u001b[39m\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcount()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y144sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_y\u001b[39m.\u001b[39;49mdrop(index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:5237\u001b[0m, in \u001b[0;36mSeries.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5140\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5142\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5149\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5150\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5151\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5152\u001b[0m \u001b[39m    Return Series with specified index labels removed.\u001b[39;00m\n\u001b[0;32m   5153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5235\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   5236\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5238\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5239\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5240\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5241\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5242\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5243\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5244\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5245\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[0] not found in axis'"
     ]
    }
   ],
   "source": [
    "print(f'Number of 1s: {train_y[train_y == 1].count()}')\n",
    "print(f'Number of 0s: {train_y[train_y == 0].count()}')\n",
    "\n",
    "train_y.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[0] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\renae\\OneDrive\\Documentos\\Academicos\\MachineLearning\\titanic\\training.ipynb Cell 72\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y146sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m50\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y146sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39mif\u001b[39;00m (train_y\u001b[39m.\u001b[39miloc[[i]] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/renae/OneDrive/Documentos/Academicos/MachineLearning/titanic/training.ipynb#Y146sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         new_train_y \u001b[39m=\u001b[39m train_y\u001b[39m.\u001b[39;49mdrop(index \u001b[39m=\u001b[39;49m i)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:5237\u001b[0m, in \u001b[0;36mSeries.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5140\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   5141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m   5142\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5149\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   5150\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   5151\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   5152\u001b[0m \u001b[39m    Return Series with specified index labels removed.\u001b[39;00m\n\u001b[0;32m   5153\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5235\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   5236\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   5238\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   5239\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   5240\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   5241\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   5242\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   5243\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   5244\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   5245\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\renae\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6934\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6932\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6933\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6934\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6935\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6936\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: '[0] not found in axis'"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    if (train_y.iloc[[i]] == 0).values[0]:\n",
    "        new_train_y = train_y.drop(index = train_y.iloc[[i]].name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
